# Transfer-Learning-in-Text-Classification
##Text Classification using ULMFit and BERT
Text Classification is a classical problem in Natural Language Processing (NLP) where certain sentences, paragraphs or documents need to be assigned to one or more predefined categories. 
Deep learning models based on recurrent structures have been able to surpass issues faced by conventional machine learning models and achieve satisfactory results in classifying text data by utilizing semantic information. While Deep Learning (DL) models have achieved state-of-the-art on many NLP tasks, these models are trained from scratch, requiring large datasets, and days to converge. These major drawbacks of DL models have been addressed through Inductive Transfer learning. Transfer Learning (TL) has thus changed the face of DL in NLP in the recent years by allowing us to take pretrained state of the art models and fine tuning them to suit the task at hand , thus obviating the need for training language models from scratch. This study, apart from exploring some DL models, would be focusing on two of the most popular TL models namely, Universal Language Model Fine Tuning (ULMFiT) and Bidirectional Encoder Representations from Transformers (BERT) that employ transfer learning to classify news articles into predefined categories. 


###Introduction
Text classification or text categorization problems in NLP aim to automatically assign one of the predefined labels to a given element of the unlabeled document space. This helps users to search for information quickly by parsing only through categories they are interested in, especially when the document space is large. Text classification is an essential component in many applications, such as spam, fraud, and bot detection (Jindal and Liu, 2007)emergency response, commercial document classification, such as for legal discovery, web searching, information filtering and sentiment analysis (Jeremy and Sebastian,2018). Text data, due to its unstructured nature is challenging on many scales, even though these are very rich source of information. One application of text classification that has evoked interests in researchers recently is News Categorization.
Generally, a text classification task can be approached in three main ways (Erik Cambria et al., 2011)
* Rule based method
* Machine Learning methods 
* Hybrid methods 
The rule-based approaches rely on a set of pre-defined rules to classify text. But creation of such rules is tiresome and requires a deep domain knowledge. Machine learning approaches however rely on past data to make such classifications.  A machine learning model can be trained on a pre labeled news corpus to learn inherent associations between words in a news article and their corresponding category.  This would enable the model to learn insights which were not previously very apparent and make decisions. Hybrid methods as the name suggests uses a combination of rule based and machine learning methods to make decisions.
News contents are one of the most important sources of information that can have a strong effect on people. A good news categorization system can help users obtain useful information in topics of interest in real time without having the need to go through millions of articles manually segregating them. Identifying emerging news topics and recommending relevant news articles based on areas of interest are two main applications of news categorization (Erik Cambria et al., 2011). Machine learning models that can automatically classify news articles could be used to identify topics of untracked news and/or make individual suggestions based on the user’s prior interests. The focus of this study would be to build robust models that take as input news headlines and short description and output news categories using not only the traditional machine learning methods but also models which employ the new state of the art methods in Deep Learning such as Transfer Learning to effectively classify the news items.


###Dataset – HuffPost Data 
HuffPost (formerly The Huffington Post) is an American news aggregator and blog, with localized and international editions. The site offers news, satire, blogs, and original content and covers politics, business, entertainment, environment, technology, popular media, lifestyle, culture, comedy, healthy living, women's interests, and local news. It was founded in 2005 by Andrew Breitbart, Arianna Huffington, Kenneth Lerer, and Jonah Peretti. The dataset, sourced from Kaggle, contains around 200k news headlines from the year 2012 to 2018. The dataset contains news articles belonging to 41 different topics. Each news record consists of several attributes such as  ‘category’, ’headline’, ’authors’, ’link’, ’short description’ and ‘date’ from which only ‘Category’, ‘Headline’ and ‘Short description’ are used in the analysis. Additionally, data attributes such as ‘Headline’ and ‘Short description’ were combined into the single attribute ‘text’ which is used as the input data for the classification task. The data was be subjected to some basic preprocessing before using it for model building.
